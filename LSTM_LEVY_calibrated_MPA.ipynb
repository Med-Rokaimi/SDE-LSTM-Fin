{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Med-Rokaimi/SDE-LSTM-Fin/blob/main/LSTM_LEVY_calibrated_MPA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#LSTM - Levy model\n"
      ],
      "metadata": {
        "id": "dZD3yVi8TQOd"
      },
      "id": "dZD3yVi8TQOd"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   The levy params are calibrated using the Marine Predators Algorithm (MPA)- metaheuristic optimiser\n",
        "*   Italy 40 index dataset\n",
        "\n",
        "*   Best solution found by MPA: {'sigma': 0.10761706439322324, 'lam': 0.30660394101146315, 'm': 1.2272103632211795, 'v': 0.4221247439535006, 'r': 2.6708324043804357}\n",
        "\n",
        "*  Best mse achieved : 0.0000040\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lxQB3iprTXWJ"
      },
      "id": "lxQB3iprTXWJ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from utils.pytorchtools import EarlyStopping\n",
        "\n",
        "from config.args import Config\n",
        "from meta_opts.MPA import MPA\n",
        "from utils.helper import save\n",
        "from data.data import create_dataset, pytorch_data_input\n",
        "from utils.evaluation import  metric\n",
        "from utils.helper import create_exp\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-07-21T12:05:53.550142700Z",
          "start_time": "2024-07-21T12:05:53.469086100Z"
        },
        "id": "afb01cade570c144"
      },
      "id": "afb01cade570c144"
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Levy solver"
      ],
      "metadata": {
        "id": "FR-J4qMpUJR1"
      },
      "id": "FR-J4qMpUJR1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Merton jump path\n",
        "def levy_solver(structure, T, steps, Npaths):\n",
        "    r,m,v,lam,sigma =structure['r'], structure['m'], structure['v'], structure['lam'], structure['sigma']\n",
        "    torch.manual_seed(4)\n",
        "    r = torch.tensor(r)\n",
        "    m = torch.tensor(m)\n",
        "    v = torch.tensor(v)\n",
        "    size = (steps, Npaths)\n",
        "    dt = T / steps\n",
        "\n",
        "    rates = torch.rand(steps, Npaths)\n",
        "    poisson = torch.poisson(rates)\n",
        "    poi_rv = torch.mul(poisson, torch.normal(m, v).cumsum(dim=0))\n",
        "    geo = torch.cumsum(((r - sigma ** 2 / 2 - lam * (m + v ** 2 * 0.5)) * dt +\n",
        "                        sigma * torch.sqrt(torch.tensor(dt)) * torch.normal(m,v)), dim=0)\n",
        "    out = torch.exp(geo + poi_rv)\n",
        "\n",
        "    return out\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-07-21T12:05:53.565305700Z",
          "start_time": "2024-07-21T12:05:53.504369500Z"
        },
        "id": "e4bc6357e3c3127e"
      },
      "id": "e4bc6357e3c3127e"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##LSTM Unit"
      ],
      "metadata": {
        "id": "8qZOZI0LUSER"
      },
      "id": "8qZOZI0LUSER"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# LSTM model\n",
        "class LSTM(nn.Module):\n",
        "\n",
        "    def __init__(self, args, input_dim, structure):\n",
        "        super(LSTM, self).__init__()\n",
        "\n",
        "        self.args = args\n",
        "        self.hidden_dim = args.hidden_units1\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = args.pred_len\n",
        "        self.layer_dim = args.num_layers\n",
        "        # LSTM layers\n",
        "        self.lstm = nn.LSTM(\n",
        "            self.input_dim, self.hidden_dim, self.layer_dim, batch_first=True, bidirectional=True, dropout=args.dropout\n",
        "        )\n",
        "\n",
        "        # Fully connected layer\n",
        "        self.fc_1 = nn.Linear(self.hidden_dim * 2, args.hidden_units2)  # fully connected\n",
        "        self.fc_2 = nn.Linear(args.hidden_units2, self.output_dim)  # fully connected last layer\n",
        "        self.relu = nn.ReLU()\n",
        "        self.structure = structure\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        sde_path = levy_solver(self.structure, self.output_dim, x.size(0), 1)\n",
        "\n",
        "        h0 = torch.zeros(self.layer_dim * 2, x.size(0), self.hidden_dim, device=x.device).requires_grad_()\n",
        "        # Initializing cell state for first input with zeros\n",
        "        c0 = torch.zeros(self.layer_dim * 2, x.size(0), self.hidden_dim, device=x.device).requires_grad_()\n",
        "\n",
        "        out, (hn, cn) = self.lstm(x, (h0, c0))\n",
        "        out = out[:, -1, :]\n",
        "\n",
        "        # Convert the final state to our desired output shape (batch_size, output_dim)\n",
        "        out = self.fc_1(out)  # first dense\n",
        "        out = self.relu(out)  # relu\n",
        "\n",
        "        out = self.fc_2(out)  # final output\n",
        "        out = out * sde_path\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-07-21T12:05:53.565305700Z",
          "start_time": "2024-07-21T12:05:53.518647600Z"
        },
        "id": "41a668bce5fb3343"
      },
      "id": "41a668bce5fb3343"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Trainer class"
      ],
      "metadata": {
        "id": "SJ59mfI6UWBU"
      },
      "id": "SJ59mfI6UWBU"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "\n",
        "class TorchTrainer:\n",
        "    def __init__(self, model, loss_fn, optimizer):\n",
        "\n",
        "        self.model = model\n",
        "        self.loss_fn = loss_fn\n",
        "        self.optimizer = optimizer\n",
        "        self.train_losses = []\n",
        "        self.val_losses = []\n",
        "\n",
        "    def train_step(self, x, y):\n",
        "\n",
        "        self.model.train()\n",
        "        # Makes predictions\n",
        "        yhat = self.model(x)\n",
        "        # Computes loss\n",
        "        loss = self.loss_fn(y, yhat)\n",
        "        # Computes gradients\n",
        "\n",
        "        loss.backward()\n",
        "        # Updates parameters and zeroes gradients\n",
        "        self.optimizer.step()\n",
        "        self.optimizer.zero_grad()\n",
        "        # Returns the loss\n",
        "        return loss.item()\n",
        "\n",
        "\n",
        "    def train(self, train_loader, val_loader, batch_size, n_epochs, n_features, result_path, structure):\n",
        "        best_loss = float('inf')\n",
        "        early_stopping = EarlyStopping(patience=7, verbose=False)\n",
        "\n",
        "        import time\n",
        "        training_loss, validation_loss = [], []\n",
        "        start_time = time.time()  # Record the start time\n",
        "        for epoch in range(1, n_epochs + 1):\n",
        "            self.optimizer.zero_grad()\n",
        "            batch_losses = []\n",
        "            for x_batch, y_batch in train_loader:\n",
        "                x_batch = x_batch.view([batch_size, -1, n_features]).to(device)\n",
        "                y_batch = y_batch.to(device)\n",
        "                loss = self.train_step(x_batch, y_batch)\n",
        "                batch_losses.append(loss)\n",
        "            training_loss = np.mean(batch_losses)\n",
        "            self.train_losses.append(training_loss)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                batch_val_losses = []\n",
        "                for x_val, y_val in val_loader:\n",
        "                    x_val = x_val.view([batch_size, -1, n_features]).to(device)\n",
        "                    y_val = y_val.to(device)\n",
        "                    self.model.eval()\n",
        "                    yhat = self.model(x_val)\n",
        "                    val_loss = self.loss_fn(y_val, yhat).item()\n",
        "                    batch_val_losses.append(val_loss)\n",
        "\n",
        "                validation_loss = np.mean(batch_val_losses)\n",
        "                self.val_losses.append(validation_loss)\n",
        "\n",
        "            print(f'Epoch {epoch + 1}/{n_epochs}, Training Loss: {training_loss:.6f}, Validation Loss: {val_loss:.6f}, Best Loss : {best_loss:.6f}')\n",
        "            if val_loss < best_loss:\n",
        "                best_loss = val_loss\n",
        "                saved_model_path = save(self.model, result_path, 'best', save_model=True)\n",
        "                print(f'Best model saved with loss: {best_loss:.6f}')\n",
        "            early_stopping(val_loss, self.model)\n",
        "            if early_stopping.early_stop:\n",
        "                print(\"Early stopping\")\n",
        "\n",
        "                break\n",
        "\n",
        "        end_time = time.time()  # Record the end time\n",
        "        runtime = end_time - start_time  # Calculate the runtime\n",
        "\n",
        "        return saved_model_path, self.model, runtime\n",
        "\n",
        "\n",
        "    def evaluate(self, test_loader, batch_size=1, n_features=2):\n",
        "\n",
        "        with torch.no_grad():\n",
        "            preds = []\n",
        "            trues = []\n",
        "            for x_test, y_test in test_loader:\n",
        "                x_test = x_test.view([batch_size, -1, n_features]).to(device)\n",
        "                y_test = y_test.to(device)\n",
        "                self.model.eval()\n",
        "                yhat = self.model(x_test)\n",
        "                yhat=yhat.cpu().data.numpy()\n",
        "                preds.append(yhat)\n",
        "                y_test=y_test.cpu().data.numpy()\n",
        "                trues.append(y_test)\n",
        "\n",
        "        preds = np.array(preds)\n",
        "        trues = np.array(trues)\n",
        "        preds = preds.reshape(-1, preds.shape[-1] )\n",
        "        trues = trues.reshape(-1, trues.shape[-1])\n",
        "        return trues, preds, self.model\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-07-21T12:05:53.632406800Z",
          "start_time": "2024-07-21T12:05:53.577100500Z"
        },
        "id": "initial_id"
      },
      "id": "initial_id"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##the problem definition and objective function of the MPA"
      ],
      "metadata": {
        "id": "CBAIkZuJUb3q"
      },
      "id": "CBAIkZuJUb3q"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def decode_solution(solution, encod_data):\n",
        "    sigma = solution[0]\n",
        "    lam = solution[1]\n",
        "    r = solution[2]\n",
        "    m = solution[3]\n",
        "    v = solution[4]\n",
        "\n",
        "    return {\n",
        "        \"sigma\": sigma,\n",
        "        \"lam\": lam,\n",
        "        \"m\": m,\n",
        "        \"v\": v,\n",
        "        \"r\": r\n",
        "    }\n",
        "\n",
        "def obj_function(solution, result_path, encod_data):\n",
        "    structure = decode_solution(solution, encod_data)\n",
        "\n",
        "    model = LSTM(config, data['X_train'].shape[2], structure)\n",
        "    optimizer = getattr(torch.optim, config.opt)(model.parameters(), lr=config.lr)\n",
        "\n",
        "    loss_fn = nn.MSELoss(reduction=\"mean\")\n",
        "\n",
        "    ex = TorchTrainer(model, loss_fn=loss_fn, optimizer=optimizer)\n",
        "    input_dim = len(features)\n",
        "\n",
        "    #################################################\n",
        "    # optimising\n",
        "    #################################################\n",
        "\n",
        "    saved_model_path, trained_model, runtime = ex.train(train_loader, val_loader, batch_size=config.batch_size,\n",
        "                                                        n_epochs=config.epochs,\n",
        "                                                        n_features=input_dim, result_path=result_path, structure = structure)\n",
        "    best_model = trained_model\n",
        "    trues, preds, model = ex.evaluate(\n",
        "        test_loader_one,\n",
        "        batch_size=1,\n",
        "        n_features=input_dim)\n",
        "    print(\"opt\", ex)\n",
        "\n",
        "    preds = preds[:, -1].reshape(-1, 1)\n",
        "    trues = trues[:, -1].reshape(-1, 1)\n",
        "    print(f\" preds: {preds.shape}, trues {trues.shape}\")\n",
        "    metrics = metric(trues, preds)\n",
        "\n",
        "    return metrics['mse'], trues, preds\n",
        "\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-07-21T12:05:53.632406800Z",
          "start_time": "2024-07-21T12:05:53.587088500Z"
        },
        "id": "db8c9edd418b062f"
      },
      "id": "db8c9edd418b062f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "   # GWO solution bundries\n",
        "\n",
        "LB = [0,0, 0, 0, 0]\n",
        "UB = [4.99, 4.99, 4.99, 4.99, 4.99]\n",
        "\n",
        "problem = {\n",
        "        \"fit_func\": obj_function,\n",
        "        \"lb\": LB,\n",
        "        \"ub\": UB,\n",
        "        \"minmax\": \"min\",\n",
        "        \"verbose\": True,\n",
        "        \"save_population\": False,\n",
        "        \"log_to\": \"console\",\n",
        "        \"dataset\": {}\n",
        "    }\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-07-21T12:05:53.632406800Z",
          "start_time": "2024-07-21T12:05:53.613206200Z"
        },
        "id": "d25403d68197e50f"
      },
      "id": "d25403d68197e50f"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## the main function"
      ],
      "metadata": {
        "id": "YFEGQYCSUpjd"
      },
      "id": "YFEGQYCSUpjd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "\n",
        "################################################\n",
        "# Experimin SetUp\n",
        "################################################\n",
        "\n",
        "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "torch_seed, rs_seed = 2012, 4\n",
        "torch.manual_seed(torch_seed)\n",
        "rs = np.random.RandomState(rs_seed)\n",
        "\n",
        "result_path = \"./results\"\n",
        "EXCEL_EXP_PATH = \"./results/exp.xlsx\"\n",
        "saved_model_path = \"\"\n",
        "dataset_name = \"Brent.csv\"\n",
        "dataset_path = 'dataset/' + dataset_name\n",
        "target_column = 'Price'  # the column name of the target time series (brent or WTI)\n",
        "\n",
        "model_decriptipn = 'LSTM + Merton Jump '\n",
        "model_name = 'LSTM_Levy_Merton_calibrated by mpa'\n",
        "save_model = True\n",
        "config = Config(\n",
        "    epochs=300,\n",
        "    pred_len=1,\n",
        "    seq_len=10,\n",
        "    n_critic=1,\n",
        "    model_name=model_name,\n",
        "    dataset=target_column,\n",
        "    lr=0.003054,\n",
        "    num_layers=1,\n",
        "    dropout=0.3,\n",
        "    hidden_units1=8,\n",
        "    hidden_units2=60,\n",
        "    sde_parameters='N/A',\n",
        "    batch_size=16,\n",
        "    noise_type='normal',\n",
        "    loss='MSELoss',\n",
        "    opt='Adam',\n",
        "    seeds={'torch_seed': torch_seed, 'rs_seed': rs_seed},\n",
        "    sde='N/A'\n",
        ")\n",
        "\n",
        "\n",
        "#################################################\n",
        "# Dataset\n",
        "#################################################\n",
        "\n",
        "# read the csv file\n",
        "df = pd.read_csv(dataset_path)\n",
        "#df = df[6:]\n",
        "\n",
        "df = df[[target_column]]  # Price, WTI, SENT, GRACH\n",
        "features = df.columns\n",
        "\n",
        "\n",
        "train_size, valid_size, test_size =9019, 200,200 #3285 , 200, 200# 2040, 259, 65 #2000, 180, 200\n",
        "data = create_dataset(df, target_column, train_size, valid_size, test_size, config.seq_len, config.pred_len)\n",
        "train_loader, val_loader, test_loader , test_loader_one = pytorch_data_input(data, config.batch_size )\n",
        "print(f\"Data : {dataset_name}, {data['X_train'].shape} , {data['y_train'].shape}\")\n",
        "print()\n",
        "\n",
        "#################################################\n",
        "# create expermint instance\n",
        "#################################################\n",
        "jobID, ex_results_path = create_exp(result_path, 'exp.csv', config.model_name)\n",
        "#################################################\n",
        "# Build the model\n",
        "#################################################\n",
        "\n",
        "\n",
        "encod_data = {}\n",
        "itr = 200\n",
        "sol = MPA(obj_function, problem['lb'], problem['ub'], 5, 5, itr, 'obj_function', config, result_path,\n",
        "           encod_data)\n",
        "\n",
        "# copy solution returned from the optimiser algorithm\n",
        "best_score = sol.best\n",
        "best_solution = sol.bestIndividual\n",
        "exe_time = sol.executionTime\n",
        "\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-07-21T14:29:20.896154800Z",
          "start_time": "2024-07-21T12:05:53.682443700Z"
        },
        "id": "4360ea20e92fd31e"
      },
      "id": "4360ea20e92fd31e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------\n",
            "\n",
            "Best solution: {'sigma': 0.10761706439322324, 'lam': 0.30660394101146315, 'm': 1.2272103632211795, 'v': 0.4221247439535006, 'r': 2.6708324043804357}\n",
            "executionTime: 8606.27860879898\n",
            "Best score: 0.0000040\n",
            "--------------------------\n",
            "\n",
            "Config(epochs=300, pred_len=1, seq_len=10, n_critic=1, model_name='LSTM_Levy_Merton_calibrated by mpa', dataset='Price', lr=0.003054, num_layers=1, dropout=0.3, hidden_units1=8, hidden_units2=60, sde_parameters='N/A', batch_size=16, noise_type='normal', opt='Adam', loss='MSELoss', seeds={'torch_seed': 2012, 'rs_seed': 4}, sde='N/A')\n",
            "Index(['Price'], dtype='object')\n"
          ]
        }
      ],
      "source": [
        "# decoding\n",
        "best_sol = decode_solution(sol.Top_predator_pos, encod_data)\n",
        "print(\"--------------------------\\n\")\n",
        "print(f\"Best solution: {best_sol}\")\n",
        "print(f\"executionTime: {exe_time}\")\n",
        "mse = f\"{sol.Top_predator_fit:.7f}\"\n",
        "\n",
        "print(f\"Best score: {mse}\")\n",
        "print(\"--------------------------\\n\")\n",
        "\n",
        "print(config)\n",
        "print(df.columns)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-07-21T15:05:12.425493800Z",
          "start_time": "2024-07-21T15:05:12.240872200Z"
        },
        "id": "a5aa5f187a569925",
        "outputId": "016c8c15-d759-410b-a407-11135d2229e8"
      },
      "id": "a5aa5f187a569925"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [],
      "metadata": {
        "id": "158d8155c07fb5f2"
      },
      "id": "158d8155c07fb5f2"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}